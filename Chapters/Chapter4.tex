\chapter{Inpainting Sparse Sampled Epipolar-plane and Computing Depth Map}
\label{chap:Inpainting_sparse}

We just presented in Subsection~\ref{sec:shearlet_parseval_inpainting} a general framework for image inpainting using Parseval Frames and we also presented the comparison of general Shearlet Parseval Frames (which include Universal Shearlets, $\alpha$-Shearlets and Cone Adapted Shearlets) and Wavelet Parseval Frames in the task of inpainting a line-distribution singularity, having the conclusion that Shearlets are better by its directional sensitivity.

\bigskip

We also presented in Subsection~\ref{sec:0-Shearlets} the particular case of Universal Shearlets with scaling sequence given by the parameters $\alpha_j=-2/j$, which generates a Parseval frame that is a good choice for the represenation of singularities distributed over straight lines, and therefore is a good option for inpainting Epipolar Plane Images that are formed by linear structures.

\bigskip

In this chapter we will present a particular algorithm that we used to inpaint EPIs related to sparse sampled light fields using $0$-Shearlets in the Julia implemenation of Shearlab (Shearlab.jl) which is called Iterative Hard Thresholding; we will also present the results on the impainting for a particular data set (the Church Data set already mentioned in Chapter 2). 

\bigskip

Using the inpainted EPIs we will present a line detection algorithm called Hough Line Transform that allows us to get the slopes of the lines related to different features in in the EPIs and therefore let us compute the depth map of the scene concluding the light field reconstruction task that we were looking for in this thesis. 

\section{Iterative thresholding algorithm for EPIs inpainting using $0$-Shearlets}

To formulate the light field reconstruction algorithm in discrete domain we will assume that that the starting coarse set of views is a downsampled version of the unknown densely sampled light field we are trying to reconstruct. The uniformly distributed cameras imply the possibility of estimating a common upper bound of disparities between consecutive views that we will call $d_{\text{max}}$; as we saw in Subsection~\ref{sec:phys_setup_sampling_rate} for densely sampled EPI's one need to ensure maximum 1 pixel disparity between nearby views (this in order to avoid aliasing and other artifacts), this representing minimum sampling rate law similar to Nyquist-Shannon sampling theorem. The given sparse set of views are regarded as taken at each $d_{max}=\lceil d_{max}\rceil$-th view of a densely sampled Light Field. 

\bigskip


As a very illustrative example one refers to the Figure~\ref{fig:sparse_EPI} where we have an EPI representation of four views with 16 pix disparity; we also established in Subsection~\ref{sec:phys_setup_sampling_rate} that it is sufficient to compute the slope of the lines representing certain scene points in the Epipolar plane images to know the relative depth in the scene of the correspondent feature point, this using the equation~\ref{eq:C2S5E4}; for that we will need to be able to see clear straight lines in the EPIs.

\bigskip

On Figure~\ref{fig:sparse_EPI} (a) one can see an sparse sampled Epipolar Plane Image, where the lines are not distinguishable; on Figure~\ref{fig:sparse_EPI}(b) when we separate the layers of the sparse sampled Epipolar Plane Image with 16px of disparity between the consecutive views the lines start to form; and finally the lines are clear in Figure~\ref{fig:sparse_EPI}(c), that represents the correspondent densely sampled Epipolar Plane Image which we want to recover by inpainting the sparse version. 

\bigskip

To proceed with the mathematics of the optimization problem that performs the inpainting, we will assume that the densely sampled EPI is a square image denoted by $y^*\in \mathbb{R}^{N\times N}$ where $N=md_{max}$ and $m$ is a number of avialable views. Given the samples $y\in\mathbb{R}^{N\times N}$ of the dense $y^*$ obtained by 

\begin{equation}
\label{eq:lfshearlets7}
y(i,j)=M(i,j)y^*(i,j)
\end{equation}

where $M\in\mathbb{R}^{N\times N}$ is a measuring matrix from which one can get the mask for the inpainting problem, such that $H(kd_{max},\cdot)=1$ for $k=1,\ldots,m$ and $0$ elsewhere. The measurements $y$ form an incomplete EPI where only rows from the available images are presented, while everywhere else EPI values are $0$. We can rewrite the Equation~\ref{eq:lfshearlets7} as $y=Hy^*$ by lexicographically reordering the variables $y,y^*\in \mathbb{R}^{N^2}$, $H\in\mathbb{R}^{N^2\times N^2}$. 

\bigskip 

Let $\mathcal{SH}(\psi,\phi,(-2/j)_j\in\mathbb{Z})$ be the system of $0$-Shearlets, defined in the Subsection~\ref{sec:0-Shearlets}; in addition let $S:\mathbb{R}^{N\times N}\longrightarrow \mathbb{R}^{N\times N\times\eta}$ and $S^*: \mathbb{R}^{N\times N\times\eta}\longrightarrow \mathbb{R}^{N\times N}$ the analysis and synthesis operator related to the $0$-Shearlet system defined in equations~\ref{eq:0analysis} and~\ref{eq:0synthesis}, where $\eta$ is the number of all translation invariant transform elements.

\bigskip 

The reconstruction problem of $y^*$ defined by the sampling matrix $M$ and the measurements $y$ can be cast as an inpainting problem following the framework of Subsection~\ref{sec:shearlet_parseval_inpainting} given by,

\begin{equation}
\label{eq:lfshearlets8}
x^*=\underset{x\in\mathbb{R}^{N\times N}}{\textrm{argmin}}||S(x)||_1,\quad \textrm{subject to}\quad y=Mx
\end{equation}

\bigskip

The algorithm that we will use to solve the optimization problem will make use of iterative procedures applied in morphological component analysis approaches, which have been originally proposed for decomposing images into piecewise-smooth and texture parts (see \cite{morph} and \cite{mcalab}), this algorithm is also known as Iterative Hard Thresholding. Following the approach of Vagharshakyan \cite{LF-Shearlets}, we aim to recunstruct the EPI $y^*$ by performing regularization in the shearlet transform domain by its sparsifying properties for cartoon-like functions. 

\bigskip

The solution is sought in the form of the algorithm~\ref{alg:lfshearlets1}. 

\begin{algorithm}[h!]
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
		\SetKwInOut{Compute}{Compute}

    \Input{Sparse EPI $y$, sampling matrix $M$, $\delta_{init}$,$\delta_{min}$, iterations}
		\Compute{$x_0:=0$;\\
						 $\delta_0:=\delta_{init}$;\\
						 $\lambda:=(\delta_{min})^{1/(iterations-1)}$;\\
						 $\Gamma_0 := \textrm{supp}(S(x_0))$;\\
					   $\beta_0 := S_{\Gamma_0}(y-Mx_0)$;\\
						 $\alpha_0 =\frac{||\beta_0||_2^2}{||MS^*(\beta_0)||_2^2}$;\\
						 \textbf{for} $n:=0$ \textbf{to} (iterations-1) \textbf{do}\\
							 \hspace{5mm} $x_{n+1}=S^*(T_{\delta_n}(S(x_n+\alpha_n(y-Mx_n))))$;\\
							 \hspace{5mm} $\Gamma_{n+1} := \textrm{supp}(S(x_{n+1}))$;\\
					     \hspace{5mm} $\beta_{n+1} := S_{\Gamma_{n+1}}(y-Mx_{n+1})$;\\
						 	 \hspace{5mm} $\alpha_{n+1}: =\frac{||\beta_{n+1}||_2^2}{||MS^*(\beta_{n+1})||}$;\\
							 \hspace{5mm} $\delta_{n+1} :=\lambda\delta_n;$\\
							\textbf{end}}
    \Output{Inpainted EPI $x_{iterations}$}
    \caption{Inpainting via iterative hard thresholding}
		\label{alg:lfshearlets1}
\end{algorithm}

\bigskip

In the Algorithm~\ref{alg:lfshearlets1}, the operator $T_{\delta}$ is the hard thresholding operator given by:

$$
(T_{\delta}x)(k)=\begin{cases} x(k)\textrm{,}\quad |x(k)|\geq \delta \\ 0\textrm{,}\quad |x(k)|<\delta \end{cases}
$$

The thresholding level $\delta_n$ decreases with the iteration number linearly in the range $[\lambda_{max},\lambda_{min}]$. The sequence $x_n$ that converges to $x^*$ reaches a solution of the problem~\ref{eq:lfshearlets8}, we refer to Figure~\ref{fig:EPI_rec} for the complete pipeline of the reconstruction method.

\bigskip

Here $\alpha_n$ is an acceleration parameter; in the usual inpainting algorithms based on the Shearlet Transform the chosen parameter is $\alpha_n=1$ (see \cite{Analysisinpaint} and \cite{Shearlab}) but the convergence in this case is slow and can be accelerated by using $\alpha_n>1$. It is also not optimal to take alpha too high, since this can cause instability. One can see on Figure~\ref{fig:alpha_accel} that convergence speed increases when increasing fixed values $\alpha_n = \alpha$ up to some level where the algorithm starts to diverge.

\begin{figure}[h!]
\centering
\includegraphics[width = 0.9 \textwidth]{./Diagrams/alpha_accel.jpg}
\caption{Reconstruction performance (expressed in terms of Peak Signal-to-Noise radio) dependence on acceleration coefficients $alpha_n$, for contant value for all iterations $\alpha_n=\alpha$, increasing $\alpha$ brings accelerating convergence, but after some limit, the reconstruction starts to diverge ($\alpha = 20$). Figure taken from \cite{LF-Shearlets} pp. 7}
\label{fig:alpha_accel}
\end{figure}

The approach that we will use and is presented in Algorithm~\ref{alg:lfshearlets1} was proposed by T. Blumensath and M. Davies in 2010 in their article "Normalised Iterative Hard Thresholding; guaranteed stability and performance" \cite{hard-thresholding}. This algorithm applies an iteration-adaptative selection of the parameter given by

$$
\alpha_n=\frac{||\beta_n||_2^2}{||MS^*(\beta_n)||_2^2}
$$

where $\beta_n=S_{\Gamma_n}(y-Mx_n)$ and $S_{\Gamma_n}$ is the shearlet transform decomposition only for coefficients from $\Gamma_n=\textrm{supp}(S(x_n))$; is important to be noticed that $||\cdot||_2$ is the Eucledian norm in the associated $N^2\eta$-dimensional Eucledian space of $\mathbb{R}^{N\times N\times \eta}$ with elements arranged in lexicographic order. The convergence rate of the adaptative selection is also illustrated in Figure~\ref{fig:alpha_accel} and one can see that the adaptation provides high convergence speed and stable reconstruction we refer to the original paper \cite{hard-thresholding} for a more detailed analysis of the convergence and stability conditions, which for our case are fulfilled using the fact that the $0$-Shearlets system form a Parseval Frame. 

\bigskip

As we discurssed in Subsection~\ref{sec:0-Shearlets} we are not obligated to use all the general shearlet transform atoms, instead we favor the use of atoms which are associated with valid directions in EPI; the support of those atomes is illustrated in Figure~\ref{fig:LFshearlets2f}. The scales of the shearlet transform are constructed in dyadic manner, therefore we are choosing $J = \lceil log_2 d_{max}\rceil$ number of scales. In order to perform this programatically using the software Shearlab.jl in every scale we choose $2^{j+1}+1$ shears ($j=0,\ldots, J-1$) to cover the region.

\bigskip

Finally, in the following subsections we will present the resulting inpainted EPIs of the Church data set, as well as the technique that we use to detect lines in the inpainted EPIs and finally compute the depth map. 

\section{Results of sparse EPIs inpaiting}

In order to give the full picture of the EPIs inpainting algorithm implementation and results, we will present the set of ideas that made us take some decisions in the way to design the implementation of the inpainting algorithm.

\bigskip 

As we presented to Section~\ref{sec:Sparse-acquisition} the data set that we used was a series of pictures of a Church, given by the research group of Professor Markus Gross in the Disney Research Center. The data set has 100 different views of the scene, we present in~\ref{fig:first_church},~\ref{fig:second_church} and~\ref{fig:third_church} the 1st, 55th and 100th views of the data set.

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/data_set/church_image-raw_0000_lowres.jpg}
\caption{1st picture of the Church Data Set}
\label{fig:first_church}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/data_set/church_image-raw_0055_lowres.jpg}
\caption{55th picture of the Church Data Set}
\label{fig:second_church}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/data_set/church_image-raw_0100_lowres.jpg}
\caption{100th picture of the Church Data Set}
\label{fig:third_church}
\end{figure}


\bigskip

\begin{itemize}

\item \textbf{First step (Track Points):} The first step in the implementation was the design the code to track the points; in the Subsection~\ref{sec:proc_track} we presented the followed algorithm (Lucas-Kanade method with Shi-Tomasi corner detector) whose implementation using OpenCV Python's API is presented in Appendix~\ref{sec:Appendix_A} with the results were stored in a data frame that one can find in the repository of this thesis (\url{https://github.com/arsenal9971/MThesis/blob/master/Code_notebooks/church_tracking.csv}) and are presented in Figure~\ref{fig:track_points_church}.

\bigskip

\item \textbf{Second Step (Paint sparse EPIs):}Once we had the data of the tracked points we proceed to paint the EPIs related to fixed $y$-positions in the scenes we used the julia code presented in Appendix~\ref{sec:Appendix_B}, where we used vertical strips of width $2\epsilon=16.0$ pixels to captures tracked points in the scene at different fixed $y$ positions and follow them along the different views, we also used the same data set to paint the corresponding Sparse Views with a constant disparity between consecutive views $d_{max}=7px$; this maximum disparity was chosen by trying different disparities and pick the best one in terms of the painting speed (the greater the disparity, the less time it takes to paint the sparse EPIs) and the Shearlet-based inpainting performance using a fixed number of iterations (50) in the iterative thresholding algorithm; where we measure the performance mostly in terms of how many lines of the original EPI are captured by our line detection algorithm that will be explained in the next subsection. One can see in Figure~\ref{fig:strip_disparity} the strip of points in the first image that were tracked to perform the benchmark to compute the best disparity parameter for our task; the Figure~\ref{fig:dense_disparity} is the associated densely sampled EPI and the associated sparsely sampled EPIs with different disparities $d_{max}$ are presented in Figure~\ref{fig:first_sparse_disparity},~\ref{fig:second_sparse_disparity},~\ref{fig:third_sparse_disparity} and~\ref{fig:fourth_sparse_disparity}. Finally on Figure~\ref{fig:benchmark_line} one can see the different running time obtained for different disparities (clearly the smaller the disparity, the more pictures you need to take and therefore the longest the running time); as we mentioned on Subsection~\ref{sec:proc_track} we used a Macbook Pro with OSX 10.10.5, 8GB of memory, 2.7 GHz Intel Core i5 Processor and Graphic Card Intel Iris Graphics 6100 with 1536 MB of graphic memory (relatively a low end computer system).

\bigskip

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_4_48_8_strip.png}
\caption{Strip of points of width $2\epsilon = 16.0$ px used for the benchmark to choose the disparity $d_{max}$}
\label{fig:strip_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_4_48_8_dense.png}
\caption{Densely sampled EPI associated to the points in the strip on Figure~\ref{fig:strip_disparity}}
\label{fig:dense_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_4_48_8_sparse.png}
\caption{Sparsely sampled EPI associated to the disparity $d_{max} = 4$ px}
\label{fig:first_sparse_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_7_48_8_sparse.png}
\caption{Sparsely sampled EPI associated to the disparity $d_{max} = 7$ px}
\label{fig:second_sparse_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_9_48_8_sparse.png}
\caption{Sparsely sampled EPI associated to the disparity $d_{max}=9$ px}
\label{fig:third_sparse_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_12_48_8_sparse.png}
\caption{Sparsely sampled EPI associated to the disparity $d_{max}=12$ px}
\label{fig:fourth_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/sparse_painting_benchmark.png}
\caption{Running time of painting of sparsely sampled EPIs with different disparities}
\label{fig:benchmark_line}
\end{figure}


\bigskip

One can also see in Figures~\ref{fig:first_lines_disparity},~\ref{fig:second_lines_disparity},~\ref{fig:third_lines_disparity} and~\ref{fig:fourth_lines_disparity} the lines detected in different inpainted EPIs corresponding to the same dense EPI, with different views disparity $d_max$, one can see that the important features are detected when $d_{max}=4$ and $d_{max}=7$ while when $d_{max}$ is bigger some lines are lost. 

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_4_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 4$ px}
\label{fig:first_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_7_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 7$ px}
\label{fig:second_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_9_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 9$ px}
\label{fig:third_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_12_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 12$ px}
\label{fig:fourth_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_12_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 12$ px}
\label{fig:fourth_lines_disparity}
\end{figure}

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7 \textwidth]{./Diagrams/results/Disparity_benchmark/673_10_102_12_48_8_lines.png}
\caption{Lines detected in an inpainted using disparity $d_{max} = 12$ px}
\label{fig:fourth_lines_disparity}
\end{figure}

\item \textbf{Third step (Inpaint sparse EPIs):}  

\end{itemize}

\section{Line detection in inpainted EPIs and depth map computation}

Once we have the inpaiting EPIs for our sparse set of views we need to be able to compute the slopes of the lines corresponding to different feature points; in computer vision a well known algorithm 
