\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{Adelson-Plenoptic}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Light Field Photography}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Spatio-angular parametrization of the plenoptic function for fixed $\tau $ and $\lambda $. Figure taken from Wikipedia (https://en.wikipedia.org/wiki/Light\_field)\relax }}{3}{figure.caption.5}}
\citation{Liang}
\citation{Kim-Disney}
\citation{Kim-Disney}
\citation{LF-Shearlets}
\citation{LF-Shearlets}
\citation{Ives}
\citation{Lippmann}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Three different representations of 4D LF\spacefactor \@m {}. Left: $L_4(u,v,\phi ,\theta )$. Center: $L_4(\phi _1,\theta _1,\phi _2,\theta _2)$. Right: $L_4(u,v,s,t)$. Figure taken from Wikipedia (https://en.wikipedia.org/wiki/Light\_field)\relax }}{4}{figure.caption.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Graphic representation of the two plane parametrization of a single ray on the LF which is parametrized by the intersection $(s,t)$ and $(u,v)$ with planes $\pi _0$ and $\pi _1$, respectively. Figure taken from \cite  {Kim-Disney} p.21\relax }}{4}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:C2S0F3}{{2.3}{4}{Graphic representation of the two plane parametrization of a single ray on the LF which is parametrized by the intersection $(s,t)$ and $(u,v)$ with planes $\pi _0$ and $\pi _1$, respectively. Figure taken from \cite {Kim-Disney} p.21\relax }{figure.caption.7}{}}
\citation{AdelsonBergen}
\citation{Tomasiearly}
\citation{Raytrix}
\citation{Lytro}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Stacked captured images represented in (b) from the scene setup (a). Figure taken from \cite  {LF-Shearlets} p. 2\relax }}{5}{figure.caption.8}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Light Field Photography in the History}{5}{section.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Industrial plenoptic camera Raytrix R11, produced by Raytrix. Figure taken from \url  {https://petapixel.com/assets/uploads/2010/09/raytrix.jpg}\relax }}{6}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Consumer plenoptica camera Lytro Illum, produced by Lytro. Figure taken from \url  {https://www.ephotozine.com/articles/lytro-illum-review-26434/images/highres-Lytro-Illum-6_1414410926.jpg}\relax }}{6}{figure.caption.10}}
\citation{AdelsonWang}
\citation{Lytro}
\citation{Joshi}
\citation{Veeraraghavan}
\citation{Wetzstein}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Light Field Acquisition Settings}{7}{section.2.2}}
\newlabel{sec:LF-acquisition}{{2.2}{7}{Light Field Acquisition Settings}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Diagram of Adelson and Wang design in Lytro cameras. Figure taken from \url  {https://s3.amazonaws.com/lytro-corp-assets/blog/Lytro_ILLUM.png}\relax }}{7}{figure.caption.11}}
\citation{Levoy}
\citation{Gortler}
\citation{CompressedMIT}
\citation{CompressedMIT}
\citation{LF-Shearlets}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Single coded 2D projection from the work of Wetzstein, Figure taken from \cite  {CompressedMIT} p. 8\relax }}{8}{figure.caption.12}}
\citation{Kim-Zimmer}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Typical applications for the Light Field Theory}{9}{section.2.3}}
\newlabel{sec:LF-applications}{{2.3}{9}{Typical applications for the Light Field Theory}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Downward-facing light source which induces a light field whose irradiance vectors curve otwards, Figure taken from \url  {https://en.wikipedia.org/wiki/File:Gershun-light-field-fig24.png}\relax }}{9}{figure.caption.13}}
\citation{Isaksen}
\citation{Javidi}
\citation{Ng-micro}
\citation{Pegard}
\citation{Raskar}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Geometric proxy: Stereo Vision and multiview Epipolar Geometry}{11}{section.2.4}}
\newlabel{sec:Epi-geometry}{{2.4}{11}{Geometric proxy: Stereo Vision and multiview Epipolar Geometry}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Epipolar constraint}{11}{subsection.2.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces First three of 125 images taken by Bolles et al. Figure taken from \cite  {Bolles} p. 16\relax }}{12}{figure.caption.14}}
\newlabel{fig:Bollesmultiviews}{{2.10}{12}{First three of 125 images taken by Bolles et al. Figure taken from \cite {Bolles} p. 16\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Spatiotemporal solid of data corresponding to the sequence on the Figure~\ref  {fig:Bollesmultiviews}, Figure taken from \cite  {Bolles} p.16\relax }}{12}{figure.caption.15}}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Bolles feature tracking technique and experimental setup}{13}{subsection.2.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Lateral motion with camera perpendicular to the track, Figure taken from \cite  {Bolles} p.9\relax }}{13}{figure.caption.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Lateral motion epipolar geometry, Figure taken from \cite  {Bolles} p.9\relax }}{14}{figure.caption.17}}
\newlabel{fig:LateralMotion}{{2.13}{14}{Lateral motion epipolar geometry, Figure taken from \cite {Bolles} p.9\relax }{figure.caption.17}{}}
\newlabel{eq:C1S4E1}{{2.1}{14}{Bolles feature tracking technique and experimental setup}{equation.2.4.1}{}}
\newlabel{eq:C1S4E2}{{2.2}{14}{Bolles feature tracking technique and experimental setup}{equation.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Functional analysis approach to EPI}{14}{subsection.2.4.3}}
\citation{Gupta}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Geometrical Approach to EPI}{15}{subsection.2.4.4}}
\newlabel{subsec:GeoEPI}{{2.4.4}{15}{Geometrical Approach to EPI}{subsection.2.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Stereo vision configuration, Figure taken from \cite  {Bolles} p. 14\relax }}{15}{figure.caption.18}}
\newlabel{fig:epipolarline}{{2.14}{15}{Stereo vision configuration, Figure taken from \cite {Bolles} p. 14\relax }{figure.caption.18}{}}
\citation{LF-Shearlets}
\citation{LF-Shearlets}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Epipolar plane image (EPI) formation, (a) Capturing setup, (b) Stack of captured images, (c) Example of EPI\spacefactor \@m {}. Figure taken from \cite  {LF-Shearlets} page 2\relax }}{16}{figure.caption.19}}
\newlabel{fig:EPI-dices}{{2.15}{16}{Epipolar plane image (EPI) formation, (a) Capturing setup, (b) Stack of captured images, (c) Example of EPI\@. Figure taken from \cite {LF-Shearlets} page 2\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Physical and computational setup for sparse acquisition of epipolar plane}{16}{section.2.5}}
\newlabel{sec:Sparse-acquisition}{{2.5}{16}{Physical and computational setup for sparse acquisition of epipolar plane}{section.2.5}{}}
\citation{ChangilPhD}
\citation{PointCloud}
\citation{SceneRec}
\citation{StructMot}
\citation{LF-Shearlets}
\citation{ChangilPhD}
\citation{ChangilPhD}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Physical setup and sampling rate}{17}{subsection.2.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Acquisition setup with a digital SLR camera translated by a motorized linear stage, both controlled remotely from a computer. Figure taken from \cite  {ChangilPhD} p.27\relax }}{17}{figure.caption.20}}
\newlabel{fig:setting}{{2.16}{17}{Acquisition setup with a digital SLR camera translated by a motorized linear stage, both controlled remotely from a computer. Figure taken from \cite {ChangilPhD} p.27\relax }{figure.caption.20}{}}
\citation{LF-Shearlets}
\newlabel{eq:C2S5E4}{{2.4}{18}{Physical setup and sampling rate}{equation.2.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Followed pipeline}{18}{subsection.2.5.2}}
\citation{LF-Shearlets}
\citation{LF-Shearlets}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Diagram of sparse EPI reconstruction algorithm, Figure taken from \cite  {LF-Shearlets} p. 7\relax }}{19}{figure.caption.21}}
\newlabel{fig:EPI_rec}{{2.17}{19}{Diagram of sparse EPI reconstruction algorithm, Figure taken from \cite {LF-Shearlets} p. 7\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Geometric construction of epipolar lines}{20}{subsection.2.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Epipolar line correspondent to a scene point $X$. Figure taken from \url  {http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html}\relax }}{20}{figure.caption.22}}
\newlabel{epipolar_line}{{2.18}{20}{Epipolar line correspondent to a scene point $X$. Figure taken from \url {http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html}\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces Essential Matrix. Figure taken from \url  {http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html}\relax }}{21}{figure.caption.23}}
\newlabel{fig:essential_matrix.jpg}{{2.19}{21}{Essential Matrix. Figure taken from \url {http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_epipolar_geometry/py_epipolar_geometry.html}\relax }{figure.caption.23}{}}
\newlabel{eq:C2S5E5}{{2.5}{21}{Geometric construction of epipolar lines}{equation.2.5.5}{}}
\newlabel{eq:C2S5E6}{{2.6}{21}{Geometric construction of epipolar lines}{equation.2.5.6}{}}
\citation{LearnOpenCV}
\citation{MultipleView}
\citation{SIFT}
\newlabel{eq:C2S5E7}{{2.7}{22}{Geometric construction of epipolar lines}{equation.2.5.7}{}}
\newlabel{eq:C2S5E8}{{2.8}{22}{Geometric construction of epipolar lines}{equation.2.5.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Tracking point algorithms}{22}{subsection.2.5.4}}
\citation{MVision}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Scaling a corner with constant window size does not output a corner. Figure taken from \url  {http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html}\relax }}{23}{figure.caption.24}}
\newlabel{fig:ScalingCorner}{{2.20}{23}{Scaling a corner with constant window size does not output a corner. Figure taken from \url {http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html}\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces OpenCV implementation of SIFT algorithm that detects corners of different sizes. Figure taken from \url  {http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html}\relax }}{23}{figure.caption.25}}
\newlabel{fig:dif_sizes_corners}{{2.21}{23}{OpenCV implementation of SIFT algorithm that detects corners of different sizes. Figure taken from \url {http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html}\relax }{figure.caption.25}{}}
\citation{HarrisCorner}
\citation{ShiTomasi}
\newlabel{eq:C2S4E9}{{2.9}{24}{Tracking point algorithms}{equation.2.5.9}{}}
\newlabel{eq:C2S4E10}{{2.10}{24}{Tracking point algorithms}{equation.2.5.10}{}}
\newlabel{eq:C2S4E11}{{2.11}{24}{Tracking point algorithms}{equation.2.5.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Diagrama representing the criterion of corner detection for Harris detector, the axis $x$ represents $\lambda _1$ and axis $y$ represents $\lambda _2$\relax }}{25}{figure.caption.26}}
\newlabel{fig:harris_region}{{2.22}{25}{Diagrama representing the criterion of corner detection for Harris detector, the axis $x$ represents $\lambda _1$ and axis $y$ represents $\lambda _2$\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces $\lambda _1\text  {vs.}\lambda _2$ space for Shi-Tomasi corner detector, as in Harris detector's case, the upper right area corresponds to corners, the upper left and lower right correspond to edges\relax }}{25}{figure.caption.27}}
\newlabel{fig:shitomasi_space}{{2.23}{25}{$\lambda _1\text {vs.}\lambda _2$ space for Shi-Tomasi corner detector, as in Harris detector's case, the upper right area corresponds to corners, the upper left and lower right correspond to edges\relax }{figure.caption.27}{}}
\citation{LucasKanade}
\citation{LucasKanade}
\newlabel{eq:C2S5E12}{{2.12}{26}{Tracking point algorithms}{equation.2.5.12}{}}
\newlabel{eq:C2S5E13}{{2.13}{26}{Tracking point algorithms}{equation.2.5.13}{}}
\citation{Bolles}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.5}Procedure for tracking and painting the EPIs}{27}{subsection.2.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces First image of the church data set\relax }}{27}{figure.caption.28}}
\newlabel{fig:first_frame_church}{{2.24}{27}{First image of the church data set\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces 336 corners found in the first image of the church with different colors corresponding to different features\relax }}{28}{figure.caption.29}}
\newlabel{fig:first_frame_church_points}{{2.25}{28}{336 corners found in the first image of the church with different colors corresponding to different features\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Last image of the church data set\relax }}{28}{figure.caption.30}}
\newlabel{fig:last_frame_church}{{2.26}{28}{Last image of the church data set\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces Last position of corners in the last image of the church\relax }}{29}{figure.caption.31}}
\newlabel{fig:last_frame_church_points}{{2.27}{29}{Last position of corners in the last image of the church\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Path of points tracked in the image sequence of the church, one can observe that the trajectories of the features are more or less straight lines, with some nuerical and algorithmical errors that can be ignored. The image is presented in shades of gray since the Lucas-Kanade method can be implemented with good performance in shades of gray\relax }}{29}{figure.caption.32}}
\newlabel{fig:track_points_church}{{2.28}{29}{Path of points tracked in the image sequence of the church, one can observe that the trajectories of the features are more or less straight lines, with some nuerical and algorithmical errors that can be ignored. The image is presented in shades of gray since the Lucas-Kanade method can be implemented with good performance in shades of gray\relax }{figure.caption.32}{}}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\citation{Bolles}
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces Feature point tracking for lateral camera motion. Figure taken from \cite  {Bolles} p. 16\relax }}{30}{figure.caption.33}}
\newlabel{lateral_motion_epi}{{2.29}{30}{Feature point tracking for lateral camera motion. Figure taken from \cite {Bolles} p. 16\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces EPI correspondent to some strip in the sequence of images, we are looking to get the EPI for the Church data set. Figure taken from \cite  {Bolles} p. 17\relax }}{31}{figure.caption.34}}
\newlabel{EPI_bolles}{{2.30}{31}{EPI correspondent to some strip in the sequence of images, we are looking to get the EPI for the Church data set. Figure taken from \cite {Bolles} p. 17\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces Horizontal line of a feature (house) corresponds to a diagonal strip its correspondent EPI\spacefactor \@m {}. Figure taken from \cite  {Bolles} p. 17\relax }}{31}{figure.caption.35}}
\newlabel{Feature_EPI_bolles}{{2.31}{31}{Horizontal line of a feature (house) corresponds to a diagonal strip its correspondent EPI\@. Figure taken from \cite {Bolles} p. 17\relax }{figure.caption.35}{}}
\@setckpt{Chapters/Chapter2}{
\setcounter{page}{32}
\setcounter{equation}{13}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{5}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{31}
\setcounter{table}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{Item}{10}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{16}
\setcounter{lstnumber}{1}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{float@type}{8}
\setcounter{thm}{0}
\setcounter{defn}{0}
\setcounter{con}{0}
\setcounter{lem}{0}
\setcounter{cor}{0}
\setcounter{prop}{0}
\setcounter{rem}{0}
\setcounter{ill}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
