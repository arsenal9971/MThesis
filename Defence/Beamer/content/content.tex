\begin{frame}{What is this thesis about?}
\begin{block}{}
\begin{itemize}
\item A sparsely sampled light field reconstruction method of a static scene. 

\bigskip
\pause
\item This method uses Universal Shearlets to perform an inpainting algorithm in the sparse Epipolar planes images (EPIs).

\bigskip 
\pause
\item The EPIs are images with linear structures obtained by tracking different feature points in a sequence of pictures of the scene. 

\bigskip
\pause
\item The slope of the straight lines in the EPIs can be used to compute the depth of feature points in the scene and therefore the depth map that contains the 3D information of the scene.

\bigskip
\pause
\item The thesis presents all the steps in the reconstruction pipeline with theory, algorithms and code. 
\end{itemize} 
\end{block}
\end{frame}

\begin{frame}{Involved concepts}
\begin{block}{}
\begin{itemize}
\item Early Vision (biology) and Light Field Theory (physics).

\bigskip
\pause
\item Computer Vision for point tracking and line detection (basic concepts of linear algebra).

\bigskip 
\pause
\item Functional Analysis and Computational Harmonic Analysis (sparsifying dictionaries).

\bigskip
\pause
\item Compressed sensing techniques ($\ell^1$ optimization algorithms). 
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Light Field Thoery}
\begin{block}{}
\begin{itemize}

\item In 1846 Michael Faraday proposed for the first time on his lecture "Thoughts on Ray Vibration" that light could be interpreted as a field.

\pause

\item Propagation of light rays in the 3D space is completely described by a 7D continuous function $L:\mathbb{R}^7\longrightarrow \mathbb{R}^3$, $L(x,y,z,\theta,\phi, \lambda, \tau)$ called the plenoptic function

\pause
\begin{figure}[h!]
\centering
\includegraphics[width=0.25\textwidth]{../../Diagrams/Plenoptic_function.jpg}
\end{figure}

\pause

\item The plenoptic function can be simplified to a 4D function $L_4$, called 4D Light Field or simply Light Field, which quantifies the intensity of static and monochromatic light rays propagating in half space. 
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{4D Light Field Representation}
\begin{figure}[h!]
\includegraphics[width=0.8\textwidth]{../../Diagrams/Light-field-parametrizations.jpg}
\caption{Three different representation of 4F LF\@. Left: $L_4(u,v,\phi,\theta)$. Center: $L_4(\phi_1,\theta_1,\phi_2,\theta_2)$. Right: $L_4(u,v,s,t)$.}
\end{figure}
\pause
\begin{figure}[h!]
\centering
\includegraphics[width=0.5\textwidth]{../../Diagrams/two-planes_param.jpg}
\caption{Used representation: "Two plane parametrization".}
\label{fig:C2S0F3}
\end{figure}
\end{frame}

\begin{frame}{}

\begin{center}
\textbf{\huge{Motivation}}
\end{center}

\end{frame}


\begin{frame}{Compression of High Resoluation Light Field (Wetzstein et al., 2013)}
\begin{figure}[h!]
\centering
\includegraphics[width=0.7\textwidth]{./images/compressed_light_field.pdf}
\label{fig:C2S0F3}
\end{figure}
\end{frame}

\begin{frame}{Raytrix (Perwass and Wietzke, 2010)}
\begin{figure}[h!]
\centering
\includegraphics[width=1\textwidth]{../../Diagrams/raytrix.jpg}
\label{fig:C2S0F3}
\end{figure}
\end{frame}

\begin{frame}{Lytro (Ng, 2012)}
\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{../../Diagrams/lytro.jpg}
\label{fig:C2S0F3}
\end{figure}
\end{frame}

\begin{frame}{Shearlet Representation of LF (Vagharshakyan et al., 2015)}
\begin{figure}[h!]
\centering
\includegraphics[width=1\textwidth]{./images/LightField_Shearlet.pdf}
\end{figure}
\end{frame}

\begin{frame}{Freedom of knowledge and reproducible research}

\begin{quote}
An article about computational result is \\
advertising, not scholarship. The actual \\
scholarship is the full software environment,\\
code and data, that produced the result.
\end{quote}
\begin{flushright}
\textbf{Buckheit and Donoho (1995)}
\end{flushright}
\end{frame}

\begin{frame}{Stereo Vision and Epipolar Geometry}
\begin{block}{}
\begin{itemize}
\item \textbf{Stereo Vision:} The human brain generates the 3D depth perception of its sorroundings by triangulating the points of a scene using the information coming from both eyes.

\pause
\item \textbf{Epipolar Geometry:} Generalization of Stereo Vision with more than two views, assuming the epipolar constraint.

\pause
\item \textbf{Epipolar Constraint:} Analysis of object position while assuming the knowledge of the camera motion.
\pause
\begin{figure}[h!]
\centering
\includegraphics[width=0.52\textwidth]{../../Diagrams/epipolarline.jpg}
\end{figure}
 
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Epipolar Plane Images (EPIs) on Straight Line Trajectories}
\begin{figure}[h!]
\centering
\includegraphics[width=0.45\textwidth]{../../Diagrams/perp-move.jpg}
\end{figure}

\pause
\begin{figure}[h!]
\centering
\includegraphics[width=0.90\textwidth]{../../Diagrams/EPI-dices.jpg}
\end{figure}

\end{frame}

\begin{frame}{Functional Analysis of EPIs}
\begin{block}{}
\begin{itemize}
\item \textbf{3D Light Field:} Fixing one coordinate in the focal $st$-plane $\pi_0$ of the two-parallel plane approach of 4D Light Field, one reduces the $\pi_0$ to a line, and the resulting field $L_3:\mathbb{R}^3\longrightarrow \mathbb{R}^3$ is called 3D Light Field with radiance $\mathbf{r}=L_3(u,v,s)$.

\pause
\item \textbf{Epipolar Plane Image:} By fixing on the 3D Light Field $L_3$ the $v$-coordinate on the image $uv$-plane one obtain the field $E_v:\mathbb{R}^2\longrightarrow \mathbb{R}^3$ known as the Epipolar Plane Image with radiance $\mathbf{r}=E_v(u,s)$.

\pause
\begin{figure}[h!]
\centering
\includegraphics[width=0.25\textwidth]{../../Diagrams/block1.jpg}
\end{figure}
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Depth map Estimation with EPIs}
\begin{block}{}
\begin{figure}[h!]
\includegraphics[width=0.5\textwidth]{../../Diagrams/stereo-dist.jpg}
\end{figure}
\pause
\begin{itemize}
\item \textbf{Point-depth formula:} $D= h\frac{\Delta X}{\Delta u}=h\frac{\Delta X}{u1-u2}$.
\pause
\item \textbf{Sparse sampling rate (Nyquist criterion):} $\Delta X\leq \frac{D_{min}}{h}\Delta u$.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Physical Acquisition Setup}
\begin{block}{}
\begin{itemize}
\item \textbf{Data set:} Sequence of 101 rectified pictures of a scene generated by Professor Markus Gross' group in the Disney Research Center at Zurich.
\pause
\item \textbf{Technical details of physical setup:} Canon EOS 4D Mark II DSLR camera, Canon EF 50 mm f/1.4 USM lens and a Zaber T-LST1500D motorized linear stage to drive the camera to the shooting positions with 10 mm of distance between each other. 
\pause
\begin{figure}[h!]
\includegraphics[width=0.6\textwidth]{../../Diagrams/setting.jpg}
\end{figure}
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Used Data Set: Church}
\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{../../Diagrams/first_frame_church.png}
  \end{minipage}
	\pause
 % \hfill
  \begin{minipage}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{../../Diagrams/last_frame_church.png}
  \end{minipage}
\end{figure}
\end{frame}

\begin{frame}{Followed Pipeline}
\begin{block}{}
\begin{figure}[h!]
\includegraphics[width=0.4\textwidth]{./images/pipeline.jpg}
\end{figure}
\end{block}
\end{frame}

\begin{frame}{Point Tracking Results}
\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{../../Diagrams/first_frame_church_points.png}
  \end{minipage}
	\pause
 % \hfill
  \begin{minipage}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{../../Diagrams/track_points_church.png}
  \end{minipage}
\end{figure}
\end{frame}

\begin{frame}{Particular EPI Example}
\begin{figure}[h!]
\includegraphics[width=0.45\textwidth]{../../EPIs_strips/EPIs/673_10_102_4_48_8_strip.png}
\end{figure}
\pause
\begin{figure}[!tbp]
  \centering
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{../../EPIs_strips/EPIs/673_10_102_4_48_8_dense.png}
  \end{minipage}
	\pause
 % \hfill
  \begin{minipage}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{../../EPIs_strips/EPIs/673_10_102_4_48_8_sparse.png}
  \end{minipage}
\end{figure}

\end{frame}

\begin{frame}{Reconstruction Method with Inpaiting}
\begin{block}{}
\begin{figure}[h!]
\includegraphics[width=0.7\textwidth]{../../Diagrams/sparse_EPI.jpg}
\end{figure}
\end{block}
\end{frame}

\begin{frame}{Important Tool: Frame Theory}
\begin{definition}[Frame]
Let $I$ be a set of countable indices. A sequence $(\phi_i)_{i\in I}$ in a Hilbert space $\mathcal{H}$ is called a \textbf{frame} of $H$, if there exist constants $0< A\leq B<\infty$ such that
$$
A||x||^2\leq\sum_{i\in I}|\langle x,\phi_i\rangle|^2\leq B||x||^2 \text{  ,  } \forall x\in\mathcal{H}
$$
$A$ and $B$ are called lower and upper frame bound. Moreover, if $A$ and $B$ can be chosen to be equal, we call it $(A-)$tight frame. If $A=B=1$ is possible, $(\phi_i)_{i\in I}$ forms a Parseval frame. A frame $(\phi_i)_{i\in I}$ span $\mathcal{H}$. 
\end{definition}
\end{frame}

\begin{frame}
\begin{block}{Analysis, synthesis and frame operator}
$T:\mathcal{H}\longrightarrow\ell_2(I)$ given by $f\mapsto (\langle f,\phi_i\rangle )_{i\in I}$ is called \textbf{the analysis operator}, and $T^*:\ell_2(I)\longrightarrow\mathcal{H}$, given by $(c_i)_{i\in I}\mapsto \sum_{i\in I}c_i\phi_i$ is called \textbf{the synthesis operator}.

$S=T^*T:\mathcal{H}\longrightarrow \mathcal{H}$, given by $f\mapsto \sum_{i\in I}\langle f,\phi\rangle \phi$ is called \textbf{the frame operator} and is an ivertible operator. 
\end{block}

\pause
\begin{block}{Reconstruction and Decompostion Formula}
If $(\phi_i)_{i\in I}\subseteq \mathcal{H}$ be a frame for $\mathcal{H}$, and $S$ its frame operator, then
$$
\begin{aligned}
f &=\sum_{i\in I}\langle f,\phi_i\rangle S^{-1}\phi_i \text{,  }\forall f\in\mathcal{H}\text{(Reconstruction)}\\
f &=\sum_{i\in I}\langle f,S^{-1}\phi_i\rangle\phi_i \text{,  }\forall f\in\mathcal{H}\text{(Decomposition)}
\end{aligned}
$$
\end{block}
\end{frame}

\begin{frame}{Abstract Inpainting Framework}
\begin{block}{}
\begin{itemize}
\item Let $\mathcal{H}$ a separable Hilbert space and $x^0\in\mathcal{H}=\mathcal{H}_K\oplus\mathcal{H}_M=P_K\mathcal{H}\oplus P_M\mathcal{H}$. Then, given a corrupt signal $P_K x^0$, we want to recover the missing part $P_Mx^0$.

\pause
\item In image inpanting $\mathcal{H}=L^2(\mathbb{R}^2)$, the missing space $H_M=L^2(\mathcal{M})$ for some measurable set $\mathcal{M}\subset \mathbb{R}^2$. 

\pause
\item We will assume that $x^0$ can be efficiently represented by some Parseval frame $\Phi=(\phi_i)_{i\in I}$ for $\mathcal{H}$, this is translated as asking for the solution of the $\ell^0-$minimization problem
$$
\underset{c\in\ell^2(I)}{\min}||c||_{\ell^0(I)}\quad\textrm{subject to}\quad x^0=T_{\Phi}^*c=\sum_{i\in I}c_i\phi_i
$$
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Analysis approach}
\begin{block}{}
\begin{algorithm2e}[H]
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
		\SetKwInOut{Compute}{Compute}

    \Input{Corrupted signal $P_Kx^0\in\mathcal{H}_K$, Parseval frame $\Phi=(\phi_i)_{i\in I}$ for $\mathcal{H}$}
		\Compute{\begin{equation}
			x^*=\underset{x\in\mathcal{H}}{\text{argmin}}||T_{\Phi}x||_{\ell^1(I)} \quad\textrm{subject to}\quad P_Kx^0=P_Kx
			\tag{$\ell^1-\text{INP}$}
		\end{equation}}
    \Output{recovered signal $x^*\in\mathcal{H}$}
    \caption{Inpainting via $\ell^1$-minimization}
\end{algorithm2e}
\end{block}
\end{frame}

\begin{frame}{Cone Adapted Shearlets}

\end{frame}

\begin{frame}{Universal Shearlets and $\alpha$-Shearlets}

\end{frame}

\begin{frame}{Shearlet-based inpainting with iterative hard thresholding}

\end{frame}

\begin{frame}{Line detection and depth map estimation}

\end{frame}

\begin{frame}{Conclusions and Outlook}

\end{frame}

\begin{frame}{Thanks!}
\begin{center}
\Large{Questions?}
\end{center}
\begin{figure}[h!]
\centering
\includegraphics[width=0.8\textwidth]{./Images/lf-camera.jpg}
\end{figure}
\end{frame}

